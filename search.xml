<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Deep Learning Chapter 2]]></title>
      <url>%2F2017%2F03%2F09%2FDeep-Learning-Chapter-2%2F</url>
      <content type="text"><![CDATA[在Deep Learning一书的第二章，主要介绍了线性代数的基本思想。 基本概念标量：单独的数 向量：一列数 矩阵：二维数组 张量：多维数组 在深度学习中，我们有时允许矩阵和向量相加，产生另一个矩阵：$\mathbf{C} = \mathbf{A} + \mathbf{b} $，其中 $C_{i,j} = A_{i,j} + b_j$， 即向量b和矩阵A的每一行相加。 矩阵中元素对应的乘积表示为： $\mathbf{A \odot B}$ 同时需要注意的一点是，只有非奇异的方阵才有逆。所谓非奇异也就是说，方阵的所有列向量都是线性无关的。一个列向量线性相关的方阵被称为奇异的。 范数$L^p$ 范数的定义如下：$$\left | \mathbf{x} \right |_p = (\sum_i{|x_i|^p})^{\frac{1}{p}}$$ 范数是将向量映射到非负值的函数。向量x的范数是衡量从原点到点x的距离。其需要满足下列三个条件： $f(\mathbf{x}) = 0 \Rightarrow \mathbf{x} = \mathbf{0}$ $f(\mathbf{x} + \mathbf{y}) \geq f(\mathbf{x}) + f(\mathbf{y})$ (三角不等式) $ \forall \alpha \in \mathbb{R}, f(\alpha \mathbf{x}) = |\alpha| f(\mathbf{x}) $ p = 2时，$L^2$被称为欧几里得范数，表示的是原点和x之间的欧氏距离。 平方$L^2$范数： $\mathbf{x}^T x$。 平方$L^2$范数较之$L^2$范数更加的方便，因为前者的导数只和对应元素相关，而后者的导数却是和整个向量相关。 但是有时我们仍然会遇到在原点附近增长缓慢的情况，对于一些区分零和非零小值的机器学习应用而言是十分致命的。因此很多时候会采用$L^1$范数，每当x中的某一元素增加了一个小量时，对应的防暑也会增加这个小量。 深度学习中，我们有时为了衡量矩阵的大小，使用类似$L^2$范数的Frobenius范数： $$\left | \mathbf{A} \right |_F = \sqrt{\sum_i{A_{i,j}^2}}$$ 正交矩阵特征分解奇异值分解 SVDPCA 应用]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[从EM算法到GMM模型]]></title>
      <url>%2F2017%2F03%2F08%2F%E4%BB%8EEM%E7%AE%97%E6%B3%95%E5%88%B0GMM%E6%A8%A1%E5%9E%8B%2F</url>
      <content type="text"><![CDATA[最近温习了下机器学习经典算法之一的EM算法，顺便对GMM模型有了更加深入的理解，本文将对这两个概念进行简要介绍。 最大似然估计（MLE）Maximum Likelihood Estimation 在介绍EM算法之前，不得不提最大似然估计。 最大似然估计可以解释为： 假设 $ p (x | \omega) $ 是一个有参数向量 $\theta $ 唯一确定的概率分布 参数 $\theta $ 是固定但是未知的。 假设我们有一个按照概率分布 $ p (x | \omega) $ 的数据集 D，D 中的样本彼此独立。 MLE 就是 $\theta $ 的一个最能解释描述该数据集的值。 我们也可以通俗地解释为： 最大似然估计一般用于求分布参数 $\theta $ : 给定一个概率分布，我们从概率分布中抽n个值的采样，通过这些采样数据来估计概率分布的参数 $\theta $，定义似然函数如下所示： $$\begin{eqnarray}lik(\theta ) &amp; = &amp; f_{D}(x_{1},x_{2},…,x_{n} | \theta ) \\&amp; = &amp; \prod_{k = 1}^{N}p(x_k| \theta ))\end{eqnarray}$$ $$\theta’ = \arg \max_{\theta }\{p(Data|\theta )\}$$ 在 $\theta $ 的所以取值上令一阶导数等于0，使得这个函数取到最大值，这个使可能性最大的 $ \theta ‘ $ 值即为 $\theta $ 的最大似然估计。 最大似然估计是建立在这样的思想上：已知某个参数能使这个样本出现的概率最大，我们就把这个参数作为估计的真实值。 那么我们要如何来解决ML estimate的问题呢？ 我们先设 $\mathbf{\theta }$ 为一个p元素的向量 $\mathbf{\theta } = [\theta_1,\theta_2,…,\theta_p]^T$ 让其成为梯度算子 $ \bigtriangledown_\theta =[\frac{\partial }{\partial \theta_1}, \frac{\partial }{\partial \theta_2},…, \frac{\partial }{\partial \theta_p} ] $ 已有：$ p (x | \mathbf{\theta}) = \prod_{k=1}^{n}p(x_k | \theta)) $ 我们定义 $ l(\mathbf{\theta})$ 为最大似然函数,以及对应的梯度算子：$$l(\mathbf{\theta}) = log(p(D |\mathbf{\theta})) = \sum_{k = 1}^{n}log(p(x_k | \mathbf{\theta}))$$$$\bigtriangledown_\theta l(\mathbf{\theta}) =\bigtriangledown_\theta log(p(D |\mathbf{\theta})) = \sum_{k = 1}^{n}\bigtriangledown_\theta log(p(x_k | \mathbf{\theta}))$$ 我们通过算子为0得到最大似然估计：$$\bigtriangledown_\theta l(\mathbf{\theta}) = 0$$ ML主要应用于单高斯和多高斯中。 EM算法Expectation-Maximum Algorithm EM算法一般用于在概率模型中找最大似然估计，主要针对含有潜在变量的，将不完全的数据补成完全的。 对于含有潜在变量的，如果我们还是按照求最大似然估计的方法来解决的话（分别求偏导），会出现“和的对数”这种难以解决的情况。对于这种情况，我们要用辅助函数来帮助解决。 我们定义一个辅助函数 $ A(x,x^t)$ 与 f(x) 在 $x^t$ 处相等，且满足 $f(x) \geq A(x,x^t) $ 我们只要将辅助函数的最大值设为新的 $\theta$ ，通过多次迭代逐渐逼近 f(x) 的最大值。 我们可以利用Jensen不等式来推导： 根据Jensen不等式，我们可以得到，如果f是凸函数，x是随机变量，则：$$E[f(x)] \geq f(E[x])$$ 如果是凹函数则反之 因此我们可以推导得出一个辅助函数：(将潜在变量引入其中，log函数是凹函数) $$\begin{eqnarray}\log{p(\mathbf{X} | \Theta)} &amp; = &amp; \log{\sum_y{p(\mathbf{x},y | \Theta)}} \\&amp; = &amp; \log{q(y)\frac{\sum_y{p(\mathbf{x},y | \Theta)}}{q(y)}} \\&amp; \geq &amp; \sum_y q(y) \log(\frac{p(\mathbf{x},y | \Theta)}{q(y)})\end{eqnarray}$$ 因此，EM算法具体可以分为以下四个步骤： 对参数进行初始化设置，为 $\Theta^{old}$ E-step: 估计出 $p(y | x, \Theta^{old})$$$Q(\Theta, \Theta^{old}) = \sum_y{p(y | x, \Theta^{old}) \log(p(\mathbf{x},y|\Theta))}$$ M-step: 用最大似然估计来估计$ \Theta^{new}$$$\Theta^{new} = \arg \max_\Theta Q(\Theta, \Theta^{old})$$ 检查是否收敛，如果不是$\Theta^{new} \rightarrow \Theta^{old}$ 并返回步骤2 EM 模型主要用于高斯混合模型 GMM 中。 GMM模型Mixture ModelGaussian Mixture Model]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[做一只孤独的美食家]]></title>
      <url>%2F2017%2F02%2F23%2F%E5%81%9A%E4%B8%80%E5%8F%AA%E5%AD%A4%E7%8B%AC%E7%9A%84%E7%BE%8E%E9%A3%9F%E5%AE%B6%2F</url>
      <content type="text"><![CDATA[本篇随笔记录了一次意外的美食之行，在广州能尝到美味的怀石料理，简直是不能更满足。幸甚至哉，遂作此篇，见笑。 如果问我，生命中什么是重要的？两年前的我大概会回答说唯美食与美女不可弃，而现在的我的回答就要简练的多 —— 唯美食不可弃。看吧，不变的始终是那份对美食的热爱。 作为吃货的我有两部珍藏已久的电视剧，每当情绪低落或是想要静下心来的时候就会打开欣赏，感觉整个人一下子便获得了宁静，一种潜藏着的小喜悦变会逐渐地洋溢开来，暖却全身。这两部便是《深夜食堂》与《孤独的美食家》，一部是从家常的食物间找寻人生的真谛，一部是在平凡的生活中寻觅非凡的美味。美食即人生，两者间的交错互融才使得我们的生活更加丰富多彩。 由于要急着要简历照，我不得不在下午三点赶到珠江新城进行拍摄。在前一天预约的时候，我就心想这时间不尴不尬好生难受。拍完会学校吧，岂不枉费一次进城放荡的机会；拍完吃饭吧，又离着饭点有些遥远。 仔细这么一琢磨，我倒也觉得是该好好放松下身心了，所以就找起了周边的美食。一边找着，心里就浮现出了《孤独的美食家》中，五郎每每办完正事后在街头巷尾找寻美味的画面，以及那句在三个层层拉近的镜头后说出的“好饿啊！”。这么想着想着就怀念起了在日本吃过的那次怀石料理（脑洞好大。。。），恰逢enjoy上有一家店正搞着优惠，机不可失我便决定拍完照后前去享受一番。 说了这么多的废话，换做高中的语文阅读，这些便叫做引出主题。 写了这么多心理的执念和脑洞，此时再犹抱琵琶半遮面岂不扫兴？话不多说直接上图： 一进入餐厅落座，一封日文写的小纸条早已躺在桌台上，虽然看不太懂，但是心里总还是暖暖的。 首先端上来的就是作为吸物的时令和风汤，是由南瓜等熬制而成，入口醇厚，香甜而不腻，微咸而素雅。在今日寒风凛冽的广州可真是驱寒开胃的佳品。 由于餐厅内客人较多，服务员和我商议后决定先将第四道菜品，烧物，端上来先行品尝。这次的烧物由银鳕鱼烹制而成，配上脆爽可口的秋葵，筋道美味的菌菇，以及银鳕鱼的油而不腻，饱满而又丰腴的鱼肉一次次融化在我的舌尖，日料的美味真是让人赞不绝口。 接下来的也是我最为喜欢的，就是八寸和刺身了。这盘菜端上来的时候，服务员还特地为我一一介绍，从品种到做法到吃饭，也让我见识了一番。分别有鲜甜嫩滑的蓝鳍金枪鱼刺身，肉质厚重味道鲜美的稠鱼刺身，还有甜虾、青鱼和海螺刺身。此外还有美味的和牛寿司、土豆沙拉球、玉子烧、春卷、腌制番茄以及入口爆裂回味无穷的三文鱼籽。好一番大快朵颐！ 接下来就是香甜的和牛肉炖土豆以及鲜美的汤了 而压轴的寿司也是让我不虚此行，尤其是蓝鳍金枪鱼寿司，简直好次到炸裂！鳗鱼寿司也是软糯美味到不行！ 最后的抹茶布丁也是让我口留余香，抹茶的厚重与布丁的甜美交织在一起，升华了这次的用餐。 如果可以，做一名孤独的美食家可好？]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Deep Learning Chapter 1]]></title>
      <url>%2F2017%2F02%2F22%2FDeep-learning-Chapter-1%2F</url>
      <content type="text"><![CDATA[最近想要系统地学习下deep learning，因此找了Ian Goodfellow写的”Deep Learning”一书来啃，我会将每章所讲内容整理后放在blog上。本篇就简要介绍下deep learning一书的第一章，Introduction。 What is Deep Learning？什么是深度学习？虽然这一词早已为大家所熟知，但是这一概念可能大部分人都不胜了解。其实一张简单的韦恩图就可以清晰简洁的表示： 简单地说，深度学习是一种表示学习(representation learning)，也是一种机器学习，可用于许多AI方法。 那么深度学习又和之前的这些概念有什么区别呢？ 从这张图中我们可以看出，对于经典的机器学习方法，我们需要手动设计出特点进行导入来实现目的。而Representation Learning则是能够自己发掘特征，找到并导入来实现结果。 而对于深度学习而言，特征的找取是分多层多次实现的：先是通过原有的数据进行简单的特征提取，再根据提取的简单特征，进一步提取出更加抽象的特征来，这层递增，最终实现结果。 以图像识别的例子而言就是这样的： 第一层可以是edge，通过图像中像素值的突变来实现edge这一特征的提取； 第二层可以是corners and contours，在edge的基础上，我们可以识别出轮廓和角的边的集合，将轮廓和角等提取出来； 第三次则是object parts，通过轮廓和角的集合，我们可以测定处特定对象的整个部分； 有了上述这三个hidden layer，我们就可以最终判断出图像是哪种物体了。 Brief Introduction about the History之前我上过Ng在coursera上的“Machine Learning”课，在课的后半部分简要地带过了一些关于神经网络的知识点。如今想来，二三年前深度学习还大部分时候还是以神经网络这一概念展现在我们面前的。 的确，深度学习作为一个早已提出的概念，经历过三次发展浪潮，直到最近才以 Deep Learning 这一词示人。 在Ng课中介绍的神经网络，就是一种从神经科学的角度出发的简单的线性模型。这些模型被设计为使用一组n个输入{x1,…,xn}，并将其与一个输出y关联，这些模型希望学习一组权重{w1,…,wn},输出y=x1 w1 + … + xn wn，多层这样的结果就构成了这种早期的神经网络的雏形。一般是用back-propagation的方法来进行参数的训练。这种方法直至今日仍然是训练深度模型的主导方法。 由于多层的结构再加上多层之间的信息传递（训练时的正向、反向传播），使得这一模型也被称为神经网络模型。的确神经科学被视为深度学习研究的一个重要灵感来源，但是由于我们没有足够的关于大脑的信息来进行进一步研究指导，其作用逐渐被削弱。现在的大多数神经网络是基于一个成为Rectified linear unit的神经单元模型。 在80年代，神经网络在认知科学的背景下随着Connectionism或者说parallel distributed processing的出现而引来了又一个发展高潮。通过将大量简单的计算单元连接在一起构成网络从而实现智能的行为，用分布式表示的方法，将多个特征彼此分立开，每个输入都有多个特征表示，每个特征都参与表示多个输入，从而分立进行训练。随着back-propagation的普及，这种方法走向了潮流。 随着硬件的发展，当年遥不可及的计算代价如今得以了实现，从而引来了第三次的发展。而大量的数据集的出现也使得训练变得更为方便和准确，而模型规模的增大也使得能够实现更多复杂的内容。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Zero padding]]></title>
      <url>%2F2017%2F02%2F21%2FZero-padding%2F</url>
      <content type="text"><![CDATA[本文详细介绍在信号处理过程中的zero padding的作用和意义。 相关概念CTFT连续时间傅里叶变换(Continuous time Fourier Transform),公式在此不做赘述，表示的是连续无限长的时间域函数通过傅里叶变换转换到连续无限长的频域函数。CTFT的概念存在于物理世界中，在真正现实中处理信号时是无法得到连续信号的，必然是离散的 DTFT离散时间傅里叶变换(Discrete time Fourier Transform)，表示的是离散无限长的时间域函数通过傅里叶变换转换到连续无限长的频域函数。同样的DTFT的概念存在于信号处理的理论中，在真实处理信号时是无法得到无限长的离散采样点，必然是有限长的离散采样点。 DFT离散傅里叶变换(Discrete Fourier Transform)，表示的是有限长的离散时间域函数通过傅里叶变换转换到离散有限长的频域函数。这是我们在信号处理时采用的方法。需要注意的是，在运用DFT的时候还要注意香农定理，避免出现混叠 DFT存在的问题在实际处理信号的过程中，我们发现：由于时域采样点的个数有限，频域上的频率反映会和实际的有一定差别，如下图所示 无限长的时域函数的傅里叶变换结果： 有限长的时域函数的傅里叶变换结果 我们发现不仅会出现side lope，还会出现△f。 解决方法最简单的解决方法就是增加采样点的个数，然后在实际中由于硬件等一系列的原因，我们无法实现增加采样点，这时就可以用zero padding的方法来进行补救。 zero paddingzero padding本质上是通过在不影响结果的情况下，通过增加采样点的个数来实现对插值结果的预测，从而更好地表示变换后的细节。 时域上的 zero padding时域上的zero padding主要是在采样点后增加一定长度的值为0的点。 增加后的结果中，我们可以很明显的看到，△f明显有了减小。 频域上的 zero padding对于频域而言，zero padding之前我们要先了解频域的分布，对于一个频域函数而言，一半的位置是正负值的分水岭，而其表示直流分量的零点则表示在一头一尾处，所以我们在进行zero padding的过程中，就要先将频域函数对半切开，在中间增加为0的点。只有这样才会在不影响原有的频域的分布基础上，增加频域的范围。 我们知道，对于DFT和IDFT而言，频域点的个数和时域点的个数是相同的，所以我们在这样做之后，就相当于拓展了时域的点的个数，在原有两点中间加上了插值点，表现出了细节。 zero padding的意义不改变数据无论是频域和时域上的zero padding，都不会改变数据本身，仅仅只是改变了数据样本点的密度。 更好地体现细节无论是频域和时域上的zero padding，都增加了数据样本点的密度，等价于在对应的另一个域上进行了插值。而这个插值我们原本是无从计算的，正是通过zero padding才实现了对插值的估计。 便于应用FFT算法我们知道，快速傅里叶变换FFT算法需要 2 的 n 次方的样本点，而通过zero padding可以将样本点的个数凑成 2 的 n 次方，便于实现算法上的优化。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[我看日剧]]></title>
      <url>%2F2017%2F02%2F08%2F%E6%88%91%E7%9C%8B%E6%97%A5%E5%89%A7%2F</url>
      <content type="text"><![CDATA[关于夏天的记忆，是浴衣，花火，以及长泽雅美。而关于日剧的记忆，我想，除了帅哥美女，就是对人性的入木三分，以及，对生活的不离不弃。 大概是被《逃避虽可耻但有用》中可爱的gakki所吸引，整个寒假我都沉浸在日剧的汪洋中，从最开始“单纯”欣赏各色女主的颜，到一步步被日剧的精彩攥着一刻不想脱身。 我猜想，大部分热爱日剧的人，应该和我一样，都是通过新垣结衣、长泽雅美、山下智久或是山田孝之等盛世美颜第一次与日剧结缘。不同于某半岛国千篇一律的妖艳美丽，风流倜傥，岛国演员们给人最深的印象就是各具风骚，可以是gakki治愈人心的回眸一笑，可以是长泽大妈令人痴迷的美腿，可以是户田惠梨香调皮的兔牙······不过，自古美人如名将，不教人间见白头，仅凭颜值的话，注定是无法长久的。那么又是什么给我们以长久的追剧动力呢？ 作为一个比较理性的观众，近年来的国产剧和韩剧令我望而却步的主要原因，一是对爱情的过分追求，达到无处不在的程度。不论是刑侦还是医疗剧，主线一定是主角的爱情生活，为爱痴狂，为爱奉献，为爱牺牲。的确我不能否认，爱情是人生中重要的一环，但是生活并不仅仅只有爱情，这种将其剥离然后高高贡起的做法着实令我厌恶。 而另一主因，就是剧的深度问题。对比日剧，国产剧和韩剧更像是流水化工厂的结晶，一模一样的套路配上似曾相识的表演，完成对爱情的讴歌和才子配佳人的美好结局。作为一部青春剧，《求婚大作战》就能让我感慨“花有重开时，人无再少年”，人生需要抓住每一个当下，这样才能在回首往昔时不留遗憾，无需一次次的“哈利路亚chance”。作为一部医疗剧，《code blue》能让我在了解直升机救援的同时深入医护人员的内心，体验日式的医患关系，治人需治心。作为脑洞剧的开山怪，《父女七日变》带我们走进了青春期父女的内心世界，感触温润亲情的同时也为编剧的想象力所折服。更别提《legal high》《半泽直树》这类直击社会的写实之作，更是用坚如磐石的三观圈住了大片的饭。 从这一部部十集左右的剧中，我们所看到的不单单是丰富的情感，精彩的表演，跌宕的情节，更有着对人性的挖掘和讨论，对生活的感触和憧憬，我想这或许就是日剧在剥离一位位盛世美颜后仍能深攥人心的原因吧。 或许，在未来的某一天，我也会抛弃日剧，但是，日剧曾带给我的那份感动，那份对生活的憧憬，将在我内心留下烙印，永久不褪。 【写在最后】有人说看韩剧找不到男朋友，看日剧找不到女朋友。我希望这不是真的。。。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[巨人的陨落]]></title>
      <url>%2F2017%2F01%2F18%2F%E3%80%8A%E5%B7%A8%E4%BA%BA%E7%9A%84%E9%99%A8%E8%90%BD%E3%80%8B%2F</url>
      <content type="text"><![CDATA[都说历史是一个任人打扮的小姑娘，可架不住看客犀利的目光。从没有一段“淡妆浓抹总相宜”，浓妆艳抹和略施粉黛间的取舍全仗笔者的底蕴。 抽空拜读了肯·福莱特世纪三部曲之一的《巨人的陨落》，深有感触。其通过POV方式的以小见大，带我领略了一战前后的英德法俄美。从大国外交到战争，从权贵达官到平民百姓，书中从一位位主人公的视角出发，勾勒出了一段段充满感情的鲜活历史。 简介全书以4个国家中的5个家族为线索（俄国的别斯科夫、英国的菲兹赫伯特和威廉姆斯、德国的冯·乌尔里希、美国的杜瓦），通过第一人称POV手法，详细介绍了各自国家在一战前后的各种状况。 作者巧妙地将这5个家族定位在不同的阶级上，既有传统贵族的菲兹赫伯特与冯乌尔里希家族，也有新兴的杜瓦家族，同时还有工人阶级的威廉姆斯家族以及代表着传统俄国农民在变革时代间变迁的别斯科夫家族。 正是这巧妙的定位，使得我们得以如亲历般见证着： 一战爆发前英德法俄奥之间的外交对话。个人对这段格外着迷，以一个个国家精英的视角生动展现了国家政治外交上的隐忍与取舍。 一战中贵族的军官视角，平民的战士视角。正是一战加速了欧洲大陆传统贵族的没落。 俄国二月革命、十月革命的萌芽与诞生（列宁的归来） 战后协约国间形如分赃般的丑恶嘴脸，以及战后德国的糟糕境地。 本书以 Fall of Giants 为名，以一 fall 表示了欧洲大陆经过一战后的由盛转衰，同时还意味着战后的欧洲传统贵族开始走向了没落，战时战后尤以英国为主的妇女平权运动打破了以往男盛女衰的格局。 最令我感到惊讶的是作者写在文后的那句话 我的原则是：要么某一场景真实发生过，或者有可能发生；要么某些话真正说过，或者有可能说。如果我发现有某种原因让某种场景不可能真正发生，或不可能说出某些话——例如某个人物当时处于另一个国家，我便将其略去。 我想，这或许就是读完全文如此舒畅的原因了吧。 Thoughts如果说要让我从整本书中选出最有感触的一段，我想就要数关于俄国革命的部分了。 书中一段格雷戈里的内心活动一下子就抓住了我的心 一个孩子的成长就像一场革命，格雷戈里心想，你可以让他诞生，但后来如何就全然不在你的掌控之下了。 不像我国媒体般吹嘘十月（二月）革命的伟大，也不同西方媒体般对苏维埃敬而远之，书中以及其克制的手法，分别从俄国国内贵族和平民，以及英国贵族与平民的角度，多方面阐述了对革命的看法。 有沙皇治下的市民吃不上面包，有警察枪击手无寸铁的游行群众，也有革命之时大街上的打砸抢烧；有贵族不经审判绞死“侵占”自家空闲领地的农民，有军官贪污军需置士兵的死活与不顾，也有革命成功后苏维埃政权向贫穷农户强征口粮甚至枪毙不配合者。 的确，革命势在必行，但是在打破旧制度制定新制度的过程中，又有谁能确保自己不会成为那些打败恶龙最终成为恶龙的勇士呢？苏维埃是少数敢于站出来挑战沙皇权威的政党，以反对对人民的压迫，还人民以土地作为党的纲领，但是执政后也强抢粮食并枪毙不肯交粮的农民，甚至枪毙倒向孟什维克党的工人。 或许恶龙和勇士就是一条莫比乌斯带，我们永远不知道究竟是那一面。 写在文后：上述感想只是单纯讨论苏维埃政权，请勿发散思维！！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Head First Civilization V]]></title>
      <url>%2F2017%2F01%2F09%2FCivilization-V%2F</url>
      <content type="text"><![CDATA[开篇让我们将地球的时钟拨到远古世纪，蜿蜒的河流边正孕育着文明的曙光，一队队移民正取下行装，准备在历史的长河中书写壮丽的篇章。一座座简陋的城市如雨后春笋般拔地而起，勾勒着美好的希望。手持木棒的勇士正开疆拓土，怀揣着一统天下的梦想。 上述这些画面描述的就是文明系列游戏的开场。一把文明游戏就仿佛是人类文明盛衰兴亡的缩影，带给我的感触绝非是一般游戏可比拟的。一句话，文明系列，不仅仅是游戏。 如果说有什么游戏值得我整整一天宅在电脑前废寝忘食，那一定是席大大的文明系列。而在6代bug不断，4代画质感人的今日，5代的美丽新世界显得格外诱人，在一个又一个“next turn”的指引下，一切都如白驹过隙，一晃而逝。（友情提示，没有闹钟的，没有自制力的，请远离文明系列） 宏观看文明虽然不像P社四萌那样有着极高的历史还原度，但是在宏观层面上对人类文明的量化和物化我从未见过如文明这般卓越的。它将人类文明的核心量化为科技和文化，而各个国家的实力物化为一个个城市以及单位，彼此之间相互影响，构成了整个复杂交错的文明世界，也让玩家看到了数千年来人类文明发展的缩影，闲暇之余颇有感触。 科技与文化在Civilization这系列游戏中，人类文明时刻被文化和科技点数推进着前行。随着科技的飞速发展，科技树茁壮成长着，一个个闻所未闻的建筑和单位出现在了城市的建设列表中，等待着一国之主的召唤。它们将进一步促进科技和文化的发展。而随着文化的积累，一项项政策被从上锁的黑箱拿上了台面，如同现在的城市规划和国家方针一样，指引着帝国步入黄金时代，迈入胜利的殿堂。 的确，人类的文明从来都是一个厚积而薄发的过程，没有前期挖石头的技术，哪来之后的石油、煤矿等的大发现？没有律法的出现，哪来的意识形态的选择？纵使给远古时代的人民一百个爱因斯坦，也注定不会有相对论和量子力学的丁点萌芽。这也是为什么，在游戏中，政策的选择局限于时代，科技的研发取决于之前的积累。 城市与单位玩家通过建造城市设施和调整市民工作来实现一个城市在粮食、产能、金钱、文化和信仰等方面的平衡，使之为帝国的发展贡献力量。每每在进入城市界面时，我的脑海中浮现的不是一个个单调的数字或是乏味的图标，而是一个个活生生的市民为了生计在城市之郊辛勤工作，为城市的产能和产粮做出微不足道的贡献。这样的生化当然难言快乐，尤其是当城市人口急剧膨胀之际，辛勤劳作了一天的市民不得不蜷曲在狭小的住处休息，这也是为什么在游戏中人口和城市数量的增长会带来大幅的不快乐。于国家而言，哪里有城市，哪里就有剥削，除非危及自身统治，人民的快乐不足为道，这又何尝不是现实生活的一个缩影呢？通过产出奢侈品和建设娱乐设施，市民们的快乐可以得到大幅提升，似乎被剥削的不快早已被抛之脑后，看来娱乐至死的年代由来已久啊。 如果说用一句话总结文明系列的精髓，那就是国家的利益高于一切。在游戏界面中，渺渺众生不过是一串串简单的数字，一队队忠义无双的士兵，一个个任劳任怨的劳工。他们在玩家的带领下，为着最终的胜利默默奉献着自己。游戏中，为了保住珍贵的笑脸，我们往往不惜将攻占的城市付之一炬，看着城市的人口一回合一回合地下降，直至城池变为废墟。为了省下足够的金钱，我们往往会将多余的单位就地处决，看着他们化作一道光永远消逝在历史的长河中。为了抢在AI之前造出奇观，我们往往会强制让市民忍饥挨饿，没日没夜地为产能贡献力量。沉浸在游戏中的我们又怎会意识到呢，这些不就是曾经的“嘉定三屠”，“扬州十日”，“长平之战”后的白起杀降，布尔什维克在战后依然实施的“战时共产主义”？ 唯一带点个人色彩的也就是在城市中产出的伟人了，他们有着与真实历史中某位名人相同的名字，而在游戏中他们的命运也不外乎是为了一项奇观、一项科技、一个作品或是一场战役，鞠躬尽瘁死而后已。可即便如此，他们还是一个个义无反顾地诞生于城市，为了帝国的繁荣昌盛前赴后继。真可谓是“苟利国家生死以，岂因祸福避趋之”。 国家和城邦文明系列游戏经久不息的一个原因，就在于多样的文明种类。玩家可以从二三十个文明中挑选一个进行游戏，而这二三十个文明也都各具特色。好玩的一点在于，游戏选取这些文明中的一位著名统治者，将其作为游戏中该文明的领袖。所以在游戏界面中，我们得以看这样的场景，骑在马上的拿破仑不屑地评论着我羸弱的士兵，白宫中的华盛顿义正言辞地进行抗议，雍容华贵的武则天不怒自威地否决了我的交易。正是这些文明领袖们将我们更好地带入了游戏中，将复杂难表的国家关系用领袖们的喜怒哀乐鲜活地呈现给了玩家。 在文明游戏中，国家关系是一个很重要的部分。两国间的良好关系是进行合作研究以及现金交易的前提。同时两国间的贸易也必须在非战争状态的条件下才能进行。这不就是现实的一个缩影吗？ 除了国家之外，在游戏中玩家还会碰到许多城邦，也就是现实中的“小国”。在第一次遇到时它们会给你一些钱，我总是开玩笑地说这是供奉给大国的礼金，摆出低调的姿态祈求乱世中的苟存。刚玩的时候我总是对这些城邦不屑一顾，对这些蝼蚁一直提出的烦人任务不理不睬。看着它们一个个成为了其他国家的盟友，想着这些小国送给你们也没什么用处，就这样一直开开心心地在家种田。一转眼国际形势骤变，昔日笑脸相迎的对手最终兵戎详见，我惊讶地发现那些城邦也都紧跟着它们主子的步伐，争先恐后地对我宣战。我当时第一个想到的不是打开存档，而是“这不就是北约？”。玩得越多，我越觉得城邦好处大大的，盟友会给你兵，给你文化，给你粮食，给你资源，给你信仰，还能给你快乐！而如果觉得完成城邦任务太麻烦，大可以拿钱砸，一堆堆金子砸在城邦的脸上，玩家就能享受到如同城邦爸爸一般的待遇，给吃给喝还能帮打架。 可以说文明中对国家和城邦的设定很好地诠释出了大国与小国间的外交政策与外交姿态。 胜利种类在Civilization V这款游戏中，总共有5种胜利的方式，而这5种方式也给玩家以不同的感悟。 外交胜利有人说，联合国建立的意义是为了让全世界更好地按照大国意志来运转，而事实也确有几分相似。诸如伊拉克战争、古巴禁运等事件就是大国通过对联合国的控制来实现对小国的支配，从而更好地实现自身利益。在文明游戏中也是亦然，一旦世界议会选出了世界领袖，那么也就意味着该国有着将自己的意志以世界议会中某一议题的形式强加于他国的能力，也就实现了外交上的胜利。 征服胜利文明V这款游戏也被称为野蛮V，不打仗怎么赢天下。一个无论科技和文化都远远落后的文明要想赢得游戏，只有用武力打破现有的状态。一旦取得了所有文明的首都，就取得了征服胜利。 作为一名爱好和平的种田流玩家，从个人理念出发我是十分不喜欢玩征服胜利的，一个原因自然是因为操纵“百万大军”攻城下寨是一件极其繁琐的事。还有一个很重要的原因是我在游戏过程中探索出来的：在飞船起飞前的一回合，我抱着玩一玩的心态将我的“小男孩一号”原子弹投向了身边的埃及，瞬间一座人口30+的主城血条只剩下了一半左右，周边的单位也是死伤惨重，城市中隐约还有人群大喊哭泣的声音，虽然知道这不过是游戏一场，但是内心总感觉有些堵。当然啦，打仗是一定要打的，不过我更喜欢逼得对面割地赔款，然后我在安安心心发战争财。 科技胜利从仰望星空开始的不仅仅有哲学，还有科学！将人类文明传播到更为浩瀚的宇宙一直是科学家们的梦想，也支撑着他们燃烧自己，成就科学的跃进。当飞船起飞的一刹那，人类文明的种子已播撒在银河系中，承载着无数人的梦想驶向远方。这也是我最喜欢的胜利模式！ 文化胜利当玩家的文化支配了其他文明，当那里的人民都穿着我们的衣服，说着我们的语言的时候，我们还能说这是别的国家吗？文化胜利的本质就是通过本国文化对他国潜移默化的影响，通过人民的融合实现国家的兼并。实现难度着实不小（一般都是打出来的。。。） 时间胜利（一般都关闭时间胜利）满满都是吐槽。。。在世界末日前的那一刻，上帝说，拯救那个分数最高的文明吧，于是就有了时间胜利。。。（2050年分数最高的玩家获胜） 结尾开了程序猿的脑洞写下了这篇civilization的Head First，文明带给我的不仅仅是绝佳的游戏体验，还让我有了很多思考，打算有时间出一篇Thinking in Civilization。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Concurrent Programming]]></title>
      <url>%2F2016%2F12%2F10%2Fconcurrent-programming%2F</url>
      <content type="text"><![CDATA[并发在应用程序中起着很重要的作用，本文将详细介绍应用级的并发 进程进程是构造并发程序最为简单的方法。在CSAPP的第八章中就已经介绍过：进程本质上就是一个执行中的程序的实例，每当我们运行一个程序的时候就会创建一个进程并在其上运行相关文件。而进程在真正运行的过程中并不是独占处理器的，根据不同的逻辑控制流（每个进程的PC值），不同的进程轮流使用处理器。如果不同的进程在运行过程中有时间的重叠，则两者之间是并发的关系。采用进程的并发方式可以在父子进程之间共享文件，同时两者不同的地址可以避免彼此信息的覆盖问题。但是这种方式不得不采用IPC（进程间通信）的方式来交换彼此的信息，而这是一种开销很大的方式，大大降低运行的速度。 I/O多路复用当我们在浏览一个网页的时候，服务器可以同时处理浏览器发送的请求和用户输入的指令，而这主要采用的就是I/O多路复用的方法。其核心思想就是采用select函数，要求内核挂起进程，仅当一个或多个I/O事件发生后才将其返回给应用程序。本质上这种方法下我们创建自己的逻辑流，利用I/O多路复用来进行流的调度。这种方法的一个最大的优点就是信息交换的便捷，共享数据来得更为高效(无需在流之间切换)，使我们对程序有着更好的掌控但是与此同时，与第一种方法相比，编码量的复杂度大大提升。而且一旦某一逻辑流在读某一文本，其他流就不能读了。这也是不是很高效的一点。 线程什么是线程与进程是运行在系统中的逻辑流对应的，线程是运行在进程中的逻辑流，每个线程都有着唯一的整数ID、栈指针、栈、计数器、寄存器等等，运行在一个进程中的线程共享该进程的整个虚拟地址空间。从本质上讲，这种方法更像是上述两种方法的结合。 线程是如何执行的所有的进程在最开始的时候都是单线程的，这个线程就是主线程。随后在某一时间点主线程会创建一个对等线程并与之一起并发运行（来回切换）由于线程的context对比进程而言要小得多，所以线程之间的切换也要快得多。主线程和对等线程之间基本上是相同的，都能读写相同的共享信息。 线程相关函数创建线程1234567#include &lt;pthread.h&gt; typedef void *(func)(void *);// Returns 0 if OK, nonzero on error int pthread_create(pthread_t *tid, pthread_attr_t *attr, func *f, void *arg); // Returns thread ID of callerpthread_t pthread_self(void); 结束线程当调用下述函数时，主线程会等待所有对等线程终止时在终止自己和整个进程。否则则当线程运行完后隐式终止。 123// terminate threads#include &lt;pthread.h&gt; void pthread_exit(void *thread_return); 分离线程在线程被创建后，其默认是可结合的，即可以被其他线程回收杀死，而下面的函数则可以将其分离，仅当其终止时才自动释放存储。 123// detach threads#include &lt;pthread.h&gt; int pthread_detach(pthread_t tid); // Returns 0 if OK, nonzero on error 线程中同步变量各个线程彼此之间可以共享变量和文件，但是如果不加限制有时会造成同步错误。因此，在文件或是变量同步(读写)的过程中，并发的程序有着种种的限制。在本书讲pipeline的过程中就介绍过read after write的问题。在pipeline中如果先写后读则读的过程至少需要等待三个周期才能保证不出错（当然在forwarding的方法下我们可以将等待周期减为1个）。同样的，我们在并发线程中进行文件或是变量读写操作的时候，也会遇到类似的问题：如果在某一线程读取某一变量值的同时，另一线程正在对改写这一变量(这里的同时指的并不是完全意义上的同时，而是很短的时间)，由于读和写都要一定时间，这就可能会造成数据的错误。因此我们需要对线程间的变量同步加以限制。主要采用Posix中的 P 和 V 操作。 P(s)：加锁操作。若s非零则将其减1返回，否则挂起线程直至s非零。 V(s)：解锁操作。若有线程被P操作挂起则将s加1，重启该线程。 因此，我们可以通过 P 和 V 操作实现线程中的变量同步。以下代码展示了读者优先的线程，只要有一个读者在读，其他的读者就能忽略锁而毫无障碍的读取变量。 1234567891011121314151617181920212223// global variablesint readcnt;sem_t mutex, w;void reader(void)&#123; while(1)&#123; P(&amp;mutex); readcnt++; if (readcnt == 1) &#123; P(&amp;w); &#125; V(&amp;mutex); // do the reading P(&amp;mutex); if (readcnt == 0) &#123; V(&amp;w); &#125; V(&amp;mutex); &#125;&#125; 线程中的竞争问题如果我们在构建线程时，每次创建一个新的对等线程都是通过传递一个指向唯一整数ID的指针的话，很有可能会导致程序的错误，因为在这种情况下各个线程会产生竞争。而解决这种问题的方法也很简单，只需要用一个malloc函数为每个线程动态分配一个整数ID的指针，并将这个这个指针传递给构建线程的函数中。同时最后别忘了对指针进行free来避免memory leak。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[proxy-lab]]></title>
      <url>%2F2016%2F12%2F09%2Fproxy-lab%2F</url>
      <content type="text"><![CDATA[Proxy Lab 作为 cmu 18600 以及 15213 这两门课的最后一个lab，其综合性非常强。既需要掌握好 web programming 以及 concurrent programming 的相关知识，还需要结合之前涉及的 shell 和 cache 的相关操作。本文将详细介绍 proxy lab 的解题思路。 什么是proxy首先，我们需要知道什么是proxy？当我们平时打开浏览器的时候，输入一个URL，浏览器会向服务器发送相应的请求，服务器在接收到请求后会将相应的response发回给浏览器，如此循环往复从而加载完网页中的全部内容。此时所有的请求和响应之间的交流全是发生在 client (浏览器)和 server (服务器)之间的。而有时我们会在client和server之间添加代理，来进行相关的处理，这个代理就是实验要求我们完成的proxy。 proxy的大致示意图如下所示 实验准备在本次实验中，我们采用的浏览器是Firefox，设置代理的过程如下所示：打开设置中的高级，选择网络，点设置并按照如下设置（若proxy在本地则选择localhost或是127.0.0.1）需要注意的是，端口一定要和之后运行proxy时的端口一致 proxy如何处理request打开Firefox网页，Mac下alt + cmd + q，Win下按F12进行观察，点击每条可以显示出请求和响应的内容 通过这种方法，我们可以很轻松地看到请求和响应头。 而作为一个proxy，所需要做的事情主要有这么几件： 从请求中获取请求的方法，请求网址的hostname，path以及port（没有的话为80）(有多种方法解析，我采用的是正则表达式) 需要注意的是，本实验中不支持非get的方法，同时也不支持任何以HTTPS开头的网页请求。本实验中以501错误返回这类请求。 改变请求头中的一些内容（比如User-Agent，connection改为close） 添加 Proxy-Connection: close，来确定请求响应的交换是否结束 改变原先请求中的version。（从 HTTP/1.1 到HTTP/1.0） 对网页端发送请求进行修改之后，发送给服务器，再将response返回给网页端，如此循环往复直到网页内容加载完毕 处理多线程操作在完成上述内容之后，我们就实现了一个逐条处理网页端请求的proxy。但是在现实中这样的效率极其低下。所以对于我们的proxy还需要使其支持多线程操作。其所涉及的函数如下所示 1234int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg);int pthread_detach(pthread_t thread); 其中pthread_create函数用于打开一个新的线程，通过调用start_routine这个函数，而其中的arg是start_routine函数的参数。特别要注意的是，arg一定要事先进行malloc，为每个线程ID分配一个独立的块，并将指向这个块的指针传给start_routine。不然线程会出现竞争问题导致错误。同时在结束线程时一定要释放这些块来避免memory leak（我就是在这里跪了很久的。。。） 而第二个函数是用于在线程中防止线程被其他线程回收或杀死。 在第一步中加入上述函数，基本上就能够实现proxy的多线程操作的部分。 存储网页内容以上的proxy已经基本完成了代理的要求。不过当我们重复请求某一个网址的时候，它还是要重新加载一遍，这就有点低效了。如果我们能够把之前网页端获取的响应存下来呢？这样当我们重复加载的时候就无需连接到服务器了。所以，我们还要让我们的proxy能够存储网页的内容。在本次实验中，我用一个类似于队列的双向链表来表示存储的cache。proxy在每次处理完网页端发来的请求后，先遍历整个链表，看是否有相同的request存在cache中，如果有就直接获取对应的response。没有的话就现将请求发动到server，将server返回的response写入到cache中。在具体的操作中，我采用的是FIFO，每次都将新的request/response加在链表的头。一旦cache存储已满，就从尾部pop。需要注意的是，一旦找到匹配的request之后，我们还需要将对应的node移到链表的头指针处。这样才符合FIFO。 上述就是我对与proxy lab的总结，希望大家都能做出一个完美的proxy！！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[去雾算法浅析]]></title>
      <url>%2F2016%2F11%2F29%2F%E5%8E%BB%E9%9B%BE%E7%AE%97%E6%B3%95%E6%B5%85%E6%9E%90%2F</url>
      <content type="text"><![CDATA[何凯明博士在09年以 “Single Image Haze Removal Using Dark Channel Prior” 一文技惊四座。此文甚至成为09年的CVPR最佳论文。本篇博文将对这种去雾算法进行简要的分析，并通过自己的实现来更好的进行介绍。 算法核心介绍Foggy Image model首先，我们需要构建一个雾天图像的模型。公式如下所示，其中I表示雾天图像，J表示没有雾的图像，t表示空气穿透率，A表示纯雾。式子中的x均表示为图像中的像素点。 上式非常容易理解：我们最终看到的雾天图像是由透过空气传递过来的原始景观图像和一定浓度的雾叠加而成。 而作为去雾，我们是要依据已有的雾天图像I来得到原始的景观图像J，这就需要利用暗通道原理来求得模型中的空气穿透率t。 暗通道基于观察，何凯明博士提出了这样的假设：自然界中的大部分非天空物体，其rgb三个颜色通道中至少有一个值非常低，其表达式如下所示： 其中Ω为x*x的像素方块。 下图是先取图像中三个通道的最小值构成一张灰度图，然后在做一个一定窗口大小的最小值滤波，最终得到暗通道处理图。 通过处理图片我们可以清晰看出，除了白色的部分（三通道的值都比较大），其余部分的暗通道值很小，近似符合暗通道趋向0的假设。 去雾模型推导对于雾天模型的公式，我们现在做如下处理： 为了得到最终的去雾图像，我们需要求得t和A。推导过程如下所示： 由于即便在正常的天气中，原始景观传过来的时候也是经过了一定浓度的大气（可以认为是雾）。而对于参数A，我们是这样计算的：选取一定区域内亮度最大的值作为A（理论上认为纯雾接近纯白）这样就将t和A的值分别求了出来，从而得到去雾后的图像J。 采用这样的方法得到的图像如下所示： 由于在图像处理的过程中都不是基于一个像素而是一个像素集合的方块进行的，所以实际得到的图像中物体边缘会有比较明显的白边的存在，而对于这种现象，何凯明博士先后提出了两种理论予以解决。 去除伪影Soft Matting 2009该方法较为复杂，且处理较慢，早已不用，本文不做赘述 Guided Filter 导向滤波 2011导向滤波先做了一个如下的先验假设：所有邻近的点之间都是线性的，同时任何方程在局部的小段都可以认为是线性的。 经过推导可得： 其中q为输出图像，I为输入图像，p为滤波图像。i和k都是像素index，a和b是线性参数。在导向滤波中，I可以为任何导向图像 上述式子的一大优点就是其可以保护边界值。 通过上述式子我们可知，当像素强度变化不大时，a趋向于0而b等同于窗口的均值强度。等同于做一个均值滤波。 而当强度变化大时，a趋向于1而b趋向于0。等同于不做滤波，保留边界。 对之前的两张图片进行导向滤波处理，我们可以得到较好的结果。 总结最后我将展示一些去雾的效果： 去雾算法在处理非天空的自然物体时效果很好。如图： 同时在处理城市建筑时也有着不俗的表现。如图： 但是同时其也有着一些不足之处 比如在处理以白色物体为背景的图像时，会出现去雾效果不好以及色彩偏蓝的现象。这主要是因为去雾算法是基于暗通道值趋向为0的先验假设，而白色背景是不符合这种先验假设的，由于不符合物理模型所以才导致出错。如图： 此外当雾太厚的时候，还会出现过曝的情况，这是由于穿透参数t很小，根据之前的推导，我们会得到一个较大的J(x)。这才导致了过曝的现象。如图： 所以总而言之，去雾算法可以取得一个比较好的效果，不过也有其一定的局限性，要视具体的情况而定。 想要上手参考的，详见我的github]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[First Article]]></title>
      <url>%2F2016%2F11%2F23%2FFirst-Article%2F</url>
      <content type="text"><![CDATA[浮生偷得几日闲，遂作此blog，望与有志者相识于此。 What will be in this blog技术文作为一名计算机专业的学生，开此blog的初衷自然是强化学习的动力，促进自己去研究前沿的知识，并以博文的形式与大家共享。 随笔“意皆有所郁结，不得通其道，故述往事,思来者”，自古这就是知识分子的通病，想来我也不能例外。在本blog中，我也会时不时将自己的所想所感放上来，权当一种情绪宣泄的途径，让各位见笑。 游记二十余载间也游历了不少大好河山，附上游记既可为诸位提供行程指导，同时也为了加深这些美好的印象。 趣谈Why so serious!? Let’s have some fun. What won’t be in this blog负能量正如我们使用Python的理由——“life is short”，何苦牢骚满腹呢。虽说是情绪的宣泄，也只是抒发人生的思考，给出自己的见解，绝非自怨自艾，叹命途多舛，哀人生不公。]]></content>
    </entry>

    
  
  
</search>
